Chat inference with any llm. You may change number of cores, System prompt and Modelfile.
